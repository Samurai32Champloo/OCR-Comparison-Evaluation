{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "7128d08c36273b75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import doctr\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import PyPDF2\n",
    "from datetime import datetime\n",
    "\n",
    "# Geben Sie den Pfad zu den Poppler-Binaries an\n",
    "poppler_path = r'C:\\poppler-24.08.0\\Library\\bin'\n",
    "\n",
    "# Set the TESSDATA_PREFIX environment variable\n",
    "os.environ['TESSDATA_PREFIX'] = r'C:\\Program Files\\Tesseract-OCR\\tessdata'\n",
    "\n",
    "# Geben Sie den Pfad zur Tesseract-Ausführungsdatei an\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Initialisiere den OCR Predictor von docTR\n",
    "ocr_model = ocr_predictor('db_resnet50', 'master', pretrained=True)\n",
    "\n",
    "# Initialisiere den EasyOCR-Reader für die deutsche Sprache\n",
    "reader = easyocr.Reader(['de'])\n"
   ],
   "id": "efb935fa3bb54e7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definieren der Verzeichnisse für Eingabe, Ground Truth und Ausgaben\n",
    "# Hinweis: Die Verzeichnisse müssen an Ihre Umgebung angepasst werden\n",
    "\n",
    "# Eingabeverzeichnis für die Verarbeitung\n",
    "input_folder = Path(\"C:/Users/Input_PDF\")\n",
    "\n",
    "# Referenzverzeichnis mit Ground Truth zum Testen\n",
    "reference_folder = \"C:/Users/Ground Truth_txt\"\n",
    "\n",
    "# Erstes Ausgabeverzeichnis zum Speichern der Ergebnisse: Tesseract\n",
    "output_folder_Tesseract_txt = \"C:/Users/Output_OCR_txt_Tesseract\"\n",
    "\n",
    "# Zweites Ausgabeverzeichnis zum Speichern der Ergebnisse: docTR\n",
    "output_folder_docTR_txt = \"C:/Users/Output_OCT_txt_docTR\"\n",
    "\n",
    "# Drittes Ausgabeverzeichnis zum Speichern der Ergebnisse: easyocr\n",
    "output_folder_easyocr_txt = \"C:/Users/Output_OCR_txt_EasyOCR\""
   ],
   "id": "d20b179eeacea5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verarbeitung von PDF-Dateien mit Tesseract:",
   "id": "a447a0ceb6c31770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all PDF files in the directory\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(file, poppler_path=poppler_path)\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for image in images:\n",
    "        # Extract text from each image with German language setting\n",
    "        extracted_text += pytesseract.image_to_string(image, lang='deu') + \"\\n\"\n",
    "\n",
    "    # Save the extracted text to a .txt file\n",
    "    output_file = Path(output_folder_Tesseract_txt) / file.name.replace('.pdf', '.txt')\n",
    "    with open(output_file, 'w', encoding='utf-8') as text_file:\n",
    "        text_file.write(extracted_text)\n",
    "\n",
    "    print(f\"Extrahierter Text gespeichert in {output_file}\")"
   ],
   "id": "75f85df5b1316574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verarbeitung von PDF-Dateien mit docTR:",
   "id": "3d3fe7a48973a065"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iteriere über alle PDF-Dateien im Verzeichnis\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Lade das PDF-Dokument mit docTR\n",
    "    doc = DocumentFile.from_pdf(file)\n",
    "\n",
    "    # Verwende das OCR-Modell von docTR, um den Text zu extrahieren\n",
    "    result = ocr_model(doc)\n",
    "\n",
    "    # Extrahiere den Text aus dem Ergebnis\n",
    "    extracted_text = \"\"\n",
    "    for page in result.pages:\n",
    "        for block in page.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    extracted_text += word.value + \" \"\n",
    "                extracted_text += \"\\n\"\n",
    "            extracted_text += \"\\n\"\n",
    "        extracted_text += \"\\n\"\n",
    "\n",
    "    # Speichere den extrahierten Text in einer .txt-Datei\n",
    "    output_file = Path(output_folder_docTR_txt) / file.name.replace('.pdf', '.txt')\n",
    "    with open(output_file, 'w', encoding='utf-8') as text_file:\n",
    "        text_file.write(extracted_text)\n",
    "\n",
    "    print(f\"Extrahierter Text gespeichert in {output_file}\")"
   ],
   "id": "b557b4cf337fec4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verarbeitung von PDF-Dateien mit EasyOCR:",
   "id": "a098768d5123418a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iteriere über alle PDF-Dateien im Verzeichnis\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Konvertiere PDF-Seiten in Bilder\n",
    "    images = convert_from_path(file, poppler_path=poppler_path)\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    for image in images:\n",
    "        # Extrahiere Text aus jedem Bild mit EasyOCR\n",
    "        result = reader.readtext(np.array(image), detail=0)\n",
    "        extracted_text += \" \".join(result) + \"\\n\"\n",
    "\n",
    "    # Speichere den extrahierten Text in einer .txt-Datei\n",
    "    output_file = Path(output_folder_easyocr_txt) / file.name.replace('.pdf', '.txt')\n",
    "    with open(output_file, 'w', encoding='utf-8') as text_file:\n",
    "        text_file.write(extracted_text)\n",
    "\n",
    "    print(f\"Extrahierter Text gespeichert in {output_file}\")"
   ],
   "id": "8e059dfe19698660",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bechnung der durchschnittlichen und Standardabweichung der Confidence-Werte für Tesseract\n",
    "\n",
    "Dieser Code verarbeitet PDF-Dateien, extrahiert Text mit Tesseract und berechnet den durchschnittlichen Confidence-Wert für jedes Dokument. Am Ende werden der Gesamtdurchschnitt und die Standardabweichung der Confidence-Werte über alle Dokumente berechnet und ausgegeben."
   ],
   "id": "a0b86ff94d80b624"
  },
  {
   "metadata": {
    "tags": [
     "Correct"
    ]
   },
   "cell_type": "code",
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Define the input folder and poppler path\n",
    "input_folder = Path(\"C:/Users/Transferleistung6/Input_PDF\")\n",
    "poppler_path = r'C:\\poppler-24.08.0\\Library\\bin'\n",
    "\n",
    "def calculate_tesseract_confidence(file_path, poppler_path):\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path)\n",
    "    file_confidences = []\n",
    "\n",
    "    for image in images:\n",
    "        data = pytesseract.image_to_data(image, lang='deu', output_type=pytesseract.Output.DICT)\n",
    "        confidences = [int(conf) for conf in data['conf'] if conf != -1]\n",
    "        file_confidences.extend(confidences)\n",
    "\n",
    "    if file_confidences:\n",
    "        average_confidence = np.mean(file_confidences)\n",
    "    else:\n",
    "        average_confidence = 0\n",
    "\n",
    "    return average_confidence, file_confidences\n",
    "\n",
    "# List to store average confidence values for each document\n",
    "confidence_values = []\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Calculate the average confidence for the document\n",
    "    average_confidence, confidences = calculate_tesseract_confidence(file, poppler_path)\n",
    "    confidence_values.append(average_confidence)\n",
    "\n",
    "    # Print the confidence values for the file\n",
    "    print(f\"Average confidence for {file.name}: {average_confidence:.2f}\")\n",
    "\n",
    "# Calculate and print the overall average and standard deviation\n",
    "if confidence_values:\n",
    "    overall_average = np.mean(confidence_values)\n",
    "    overall_std_dev = np.std(confidence_values)\n",
    "    print(f\"\\nGesamtdurchschnittlicher Confidence-Wert: {overall_average:.2f}\")\n",
    "    print(f\"Gesamtstandardabweichung des Confidence-Werts: {overall_std_dev:.2f}\")\n",
    "else:\n",
    "    print(\"\\nKeine Dokumente gefunden oder keine Confidence-Werte berechnet.\")"
   ],
   "id": "d13bde621bf62f4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bechnung der durchschnittlichen und Standardabweichung der Confidence-Werte für EasyOCR\n",
    "\n",
    "Dieser Code verarbeitet PDF-Dateien, extrahiert Text mit EasyOCR und berechnet den durchschnittlichen Confidence-Wert für jedes Dokument. Am Ende werden der Gesamtdurchschnitt und die Standardabweichung der Confidence-Werte über alle Dokumente berechnet und ausgegeben."
   ],
   "id": "2cb21356c58abe3b"
  },
  {
   "metadata": {
    "tags": [
     "Correct"
    ]
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr\n",
    "\n",
    "# Define the input folder and poppler path\n",
    "input_folder = Path(\"C:/Users/O6819/Transferleistung6/Input_PDF\")\n",
    "poppler_path = r'C:\\poppler-24.08.0\\Library\\bin'\n",
    "\n",
    "# Create the reader for EasyOCR\n",
    "reader = easyocr.Reader(['de'])\n",
    "\n",
    "# List to store the average confidence values for each document\n",
    "confidence_values = []\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(file, poppler_path=poppler_path)\n",
    "    total_confidence = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for image in images:\n",
    "        # Extract text from each image with EasyOCR and get the confidence value\n",
    "        results = reader.readtext(np.array(image), detail=1)\n",
    "\n",
    "        for result in results:\n",
    "            _, _, confidence = result\n",
    "            total_confidence += confidence\n",
    "            total_words += 1\n",
    "\n",
    "    if total_words > 0:\n",
    "        average_confidence = total_confidence / total_words\n",
    "    else:\n",
    "        average_confidence = 0\n",
    "\n",
    "    # Store the average confidence value for the document\n",
    "    confidence_values.append(average_confidence)\n",
    "\n",
    "    # Print the average confidence value for the file\n",
    "    print(f\"Durchschnittlicher Confidence-Wert für {file.name}: {average_confidence:.2f}\")\n",
    "\n",
    "# Calculate and print the overall average and standard deviation\n",
    "if confidence_values:\n",
    "    overall_average = np.mean(confidence_values)\n",
    "    overall_std_dev = np.std(confidence_values)\n",
    "    print(f\"\\nGesamtdurchschnittlicher Confidence-Wert: {overall_average:.2f}\")\n",
    "    print(f\"Gesamtstandardabweichung des Confidence-Werts: {overall_std_dev:.2f}\")\n",
    "else:\n",
    "    print(\"\\nKeine Dokumente gefunden oder keine Confidence-Werte berechnet.\")"
   ],
   "id": "8e54e8d62ffcbe70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bechnung der durchschnittlichen und Standardabweichung der Confidence-Werte für DocTR\n",
    "\n",
    "Dieser Code verarbeitet PDF-Dateien, extrahiert Text mit DocTR und berechnet den durchschnittlichen Confidence-Wert für jedes Dokument. Am Ende werden der Gesamtdurchschnitt und die Standardabweichung der Confidence-Werte über alle Dokumente berechnet und ausgegeben."
   ],
   "id": "98e52da9269d6d25"
  },
  {
   "metadata": {
    "tags": [
     "Correct"
    ]
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import doctr\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "# Define the input folder\n",
    "input_folder = Path(\"C:/Users/O6819/Transferleistung6/Input_PDF\")\n",
    "\n",
    "def calculate_docTR_confidence(result):\n",
    "\n",
    "    all_confidences = [word.confidence for page in result.pages for block in page.blocks for line in block.lines for word in line.words]\n",
    "    return np.mean(all_confidences) if all_confidences else 0\n",
    "\n",
    "# List to store the average confidence values for each document\n",
    "confidence_values = []\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "files = input_folder.rglob('*.pdf')\n",
    "\n",
    "for file in files:\n",
    "    # Load the PDF document with docTR\n",
    "    doc = DocumentFile.from_pdf(file)\n",
    "\n",
    "    # Use the OCR model from docTR to extract text\n",
    "    result = ocr_model(doc)\n",
    "\n",
    "    # Calculate the average confidence for the document\n",
    "    average_confidence = calculate_docTR_confidence(result)\n",
    "    confidence_values.append(average_confidence)\n",
    "\n",
    "    # Print the average confidence value for the file\n",
    "    print(f\"Durchschnittlicher Confidence-Wert für {file.name}: {average_confidence:.2f}\")\n",
    "\n",
    "# Calculate and print the overall average and standard deviation\n",
    "if confidence_values:\n",
    "    overall_average = np.mean(confidence_values)\n",
    "    overall_std_dev = np.std(confidence_values)\n",
    "    print(f\"\\nGesamtdurchschnittlicher Confidence-Wert: {overall_average:.2f}\")\n",
    "    print(f\"Gesamtstandardabweichung des Confidence-Werts: {overall_std_dev:.2f}\")\n",
    "else:\n",
    "    print(\"\\nKeine Dokumente gefunden oder keine Confidence-Werte berechnet.\")"
   ],
   "id": "4a865940a5c360bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Berechnung der CER, WER und MER Fehlerquoten basierend auf Morris et al. (2004). Dieser Code nimmt einen Referenzordner, der die Ground Truth enthält, und einen Ausgabeordner, der den Output eines OCR-Anbieters enthält. Die Fehlerquoten WER (Word Error Rate), CER (Character Error Rate) und MER (Match Error Rate) werden für jede Datei berechnet und ausgegeben. Am Ende werden der Gesamtdurchschnitt und die Standardabweichung der Fehlerquoten über alle Dateien berechnet und ausgegeben.",
   "id": "db85a502f09e8b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import jiwer\n",
    "from jiwer import wer, cer, mer\n",
    "import numpy as np\n",
    "\n",
    "def compare_ocr_results(ground_truth_folder, ocr_results_folder):\n",
    "    ground_truth_folder = Path(ground_truth_folder)\n",
    "    ocr_results_folder = Path(ocr_results_folder)\n",
    "\n",
    "    wer_values = []\n",
    "    cer_values = []\n",
    "    mer_values = []\n",
    "\n",
    "    for gt_file in ground_truth_folder.glob(\"*.txt\"):\n",
    "        ocr_file = ocr_results_folder / gt_file.name\n",
    "        if ocr_file.exists():\n",
    "            with open(gt_file, 'r', encoding='utf-8') as gt, open(ocr_file, 'r', encoding='utf-8') as ocr:\n",
    "                ground_truth = gt.read()\n",
    "                ocr_result = ocr.read()\n",
    "\n",
    "                error_wer = wer(ground_truth, ocr_result) * 100\n",
    "                error_cer = cer(ground_truth, ocr_result) * 100\n",
    "                error_mer = mer(ground_truth, ocr_result) * 100\n",
    "\n",
    "                wer_values.append(error_wer)\n",
    "                cer_values.append(error_cer)\n",
    "                mer_values.append(error_mer)\n",
    "\n",
    "                print(f\"File: {gt_file.name}\")\n",
    "                print(f\"Character Error Rate (CER): {error_cer:.2f}\")\n",
    "                print(f\"Word Error Rate (WER): {error_wer:.2f}\")\n",
    "                print(f\"Match Error Rate (MER): {error_mer:.2f}\")\n",
    "                print(\"-\" * 40)\n",
    "        else:\n",
    "            print(f\"File {gt_file.name} not found in OCR results folder.\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    # Calculate and print the overall average and standard deviation for WER, CER, and MER\n",
    "    if cer_values:\n",
    "        overall_cer_avg = np.mean(cer_values)\n",
    "        overall_cer_std = np.std(cer_values)\n",
    "        print(f\"\\nGesamtdurchschnittlicher CER: {overall_cer_avg:.2f}\")\n",
    "        print(f\"Gesamtstandardabweichung des CER: {overall_cer_std:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nKeine CER-Werte berechnet.\")\n",
    "\n",
    "    if wer_values:\n",
    "        overall_wer_avg = np.mean(wer_values)\n",
    "        overall_wer_std = np.std(wer_values)\n",
    "        print(f\"\\nGesamtdurchschnittlicher WER: {overall_wer_avg:.2f}\")\n",
    "        print(f\"Gesamtstandardabweichung des WER: {overall_wer_std:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nKeine WER-Werte berechnet.\")\n",
    "\n",
    "    if mer_values:\n",
    "        overall_mer_avg = np.mean(mer_values)\n",
    "        overall_mer_std = np.std(mer_values)\n",
    "        print(f\"\\nGesamtdurchschnittlicher MER: {overall_mer_avg:.2f}\")\n",
    "        print(f\"Gesamtstandardabweichung des MER: {overall_mer_std:.2f}\")\n",
    "    else:\n",
    "        print(\"\\nKeine MER-Werte berechnet.\")\n",
    "\n",
    "# Example usage\n",
    "ground_truth_folder = \"C:/Users/Ground Truth_txt\"\n",
    "ocr_results_folder = \"C:/Users/Output_OCR_txt_EasyOCR\"\n",
    "compare_ocr_results(ground_truth_folder, ocr_results_folder)"
   ],
   "id": "963a53317b803ad9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
